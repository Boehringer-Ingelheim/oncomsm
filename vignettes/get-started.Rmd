---
title: "Get Started"
author: Kevin Kunzmann
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Get Started}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

```{r vignette-setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 6,
  fig.align = "center"
)
```

```{r setup}
library(bhmbasket.predict)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)
```

# Background

**tl;dr:** *objective response ignores time-to-first-event aspect of
endpoint. This outcome delay should be addressed when performing interim
analyses, e.g. for computing probability of success or a posterior
probability.*

In early oncology trials, (objective tumor) response based on the RECIST
criteria is often used as primary endpoint to establish the activity of
a treatment. Response is often treated as binary variable although it is
a delayed event endpoint. At the final analysis, this simplification is
of little concern since all individuals tend to be followed up long
enough to justify the assumption that non-responders are unlikely to
still become responders. This approach is often plausible since
individuals with tumors not responding to treatment ultimately progress.
However, when continuously monitoring such a trial, the assumption of
sufficient follow-up is no longer fulfilled and a simple binary analysis
may be biased.

In this vignette, the problem is addressed by extending the statistic
binary response model to a time-to-first-event model with the event of
interest being "response".

## A mixture-cure rate model for binary response data

A mixture-cure-rate model decouples the modeling of an event probability
$p$ from the corresponding time-to-event distribution. This is an
alternative to multistate modeling via cause specific hazards (???
Jackson paper). The advantage for response-rate modeling lies in the
fact that the response probability is modeled directly and that the same
prior assumptions which are valid for a Binomial model can be used as
part of the prior for a model also encompassing the time-to-response.

A mixture-cure-rate-type model for binary response assumes that the
population is a mixture of (ultimate) responders and (ultimate)
non-responders. In this context the "survival function" defines the
proportion of a population that has not experienced a response up to
time $dt$ (time since first visit of individual). The "survival
function" of the non-responder subpopulation is constantly $1$ since, by
definition, this subpopulation never experiences the event in question
(a response). The survival function of the responders, $S_r(dt)$, i.e.
the fraction of responders who did not experience a response up to $dt$,
needs to be modeled. Here we chose a Weibull distribution. A complex
(semi- or non-parametric) survival function would be next to impossible
to identify in the small data settings usually encountered in early
phase trials and the Weibull distribution is flexible enough to allow
for increasing or decreasing hazards over time. The population survival
function is then a mixture of the survival functions of the respective
subpopulation weighted by the response probability (interpreted as
proportion of responders in the overall population):
$$S(dt) = (1 - p)\,\underbrace{1}_{\hspace{-1.5cm}\text{non-responder}} + p\,\underbrace{S_r(dt)}_{\text{responder}}$$
It is clear that $p$ has the same interpretation as the response
probability in a binomial model and any prior assumption on $p$ can be
used interchangeably between the two models. The mixture-cure-rate
approach is thus a direct extension of the binomial model. However,
since time-to-response is also modeled, it is possible include
individuals who are still "at risk" of experiencing a response due to
short follow-up in a principled way. Additionally, the explicit modeling
of time-to-response allows to predict or impute not only whether an
individual at risk will ultimately become a responder or not, but also
when the response might occur.

## Recruitment

For inference about the absolute time of response since the start of a
trial for individuals who have not yet been recruited, a model for
recruitment time $t$ relative to the start of the trial is also
required. Here we choose a simple homogeneous Poisson process to model
recruitment, i.e., the recruitment rate is constant in time. We assume
that $t$ and thus $dt$ are on the scale of months.

## Observation process

The exact time of a response is not observed since the status is only
assessed during (scheduled) visits. This intermittently observed panel
data means that the response times are interval censored between the
last non-response visit and the first response visit. Note that concepts
like confirmed response can be reflected in the definition of "response"
if needed.

We furthermore assume a fixed visit spacing (on the scale of months)
i.e. that future visits occur with perfect regularity and are not
stochastic.

## Decision criterion

A quantitative decision criterion can be used to come to a decision at
the end of a trial. In early phase, this is typically the decision
whether or not to continue development of a new compound ("go"). The
space of potential decision criteria is huge and might also depend on
additional data. Here, only simple criteria based on the posterior
distribution of the response rate are considered. For instance, a
decision can be reached by checking whether the probability of exceeding
a certain target value $p_{target}$ exceeds a pre-defined confidence
level $\gamma$
$$\text{success}(r) := \underbrace{\operatorname{Pr}\big[\, p \geq p_{target} \ | \ R = r\,\big]}_{\text{posterior of exceeding target}} \geq \gamma.$$

This is equivalent to the $1-\gamma$ quantile of the posterior
distribution exceeding $p_{target}$. In settings with multiple arms, a
threshold per arm is defined.

## Probability of Success

The unconditional probability of observing a success is the Probability
of Success (PoS)
$$\operatorname{PoS} := \operatorname{Pr}\big[ \operatorname{success}(r) \,\big]$$
This probability depends on the unknown parameters and thus requires the
specification of prior distributions over

1.  the response rate $p$
2.  the Weibull shape and scale
3.  the recruitment rate

as well as a minimal follow-up time for each individual to determine
when the trial ends and a planned spacing between individual visits.

As data is accrued during the trial, PoS can be updated by model-based
imputation of the final response status of individuals still at risk
using the mixture-cure--rate model for time-to-first-event outlined
above. This allows to interpolate between the *a priori* planning PoS
and 0 (no success) or 1 (success) at the end of the trial. In practice,
this is done by sampling whether or not individuals at risk will
experience a response and if so, when the response occurs, from the
posterior predictive distribution of the Bayesian mixture-cure-rate
model.

# Example data

We consider the example of a three-arm basket trial. `bhmbasket.predict`
provides a function to simulate visit data under a simple model
(independence of arms).

```{r generate-example-data}
n_per_arm <- c(40, 30, 30)

tbl_visits <- generate_visit_data(
    group_id = c("A", "B", "C"),
    n = n_per_arm, # sample size per arm
    event_rate = c(0.33, .4, .2), 
    recruitment_rate = c(2, 1.5, 1.5), # per month
    visit_spacing = c(1.2, 1.2, 1.2), # how many months between visits?
    max_duration = 48, # in months
    event_weibull_scale = rep(4, 3),
    event_weibull_shape = rep(5, 3),
    nonevent_weibull_scale = rep(4, 3),
    nonevent_weibull_shape = rep(2, 3)
  )

tbl_visits
```

Here, `eof` stands for end of follow up and indicates whether a
particular visit is a patient's last visit. This information needs to be
stored explicitly to identify whether an individual is still "at risk"
of a response at a certain point in time. Three states `S`(table),
`P`(rogressive), `R`(responding) characterize the status of an
individual at each visit.

A plotting function for longitudinal visit-type data like this is
provided in `bhmbasket.predict`. The simulated data does not contain
post-response follow-up and duration-of-response analyses are not
currently implemented.

```{r plot-visit-data}
# epsilon is thickness of last visit state as fraction of a months
plot_visits(tbl_visits, epsilon = 15/30)
```

# Specifying a model

The model specification requires input about the prior hyperparameters
for each arm (group). Normal priors with mean and standard deviation are
used for all (transformed) parameters.

-   The response rate is parameterized in terms of its log-odds and
    additionally a minimum and maximum can be specified, which means
    that the prior is a truncated normal prior on the log-odds.

-   To make the prior on the Weibull parameters more accessible, instead
    of putting a prior on the scale parameter, a prior on the log median
    time to event and a lognormal prior on shape are used.

-   The prior for the recruitment rate is specified on the log scale and
    a maximal waiting time between recruitment of individuals can be
    given (i.e. truncating the exponential waiting time).

The sub-models for recruitment and time-to-response are specified
separately.

**Important:** The shape parameter of the time-to-response is near
unidentifiable in small data sets, hence the prior uncertainty should be
small to ensure the model is identifiable and can be sampled in a stable
way. This effectively means that the shape parameter has to be fixed *a priori*.

```{r prior-specification}
mdl <- IndependentMixtureCureRateModel(
  group_id = c("A", "B", "C"),
  logodds_mean = logodds(c(.4, .2, .2)),
  logodds_sd = c(.5, .5, .5),
  logodds_max = logodds(c(.6, .6, .6)),
  log_shape_mean = log(c(2, 2, 2)),
  log_shape_sd = c(.1, .1, .1),
  median_time_to_event_mean = c(4, 4, 4),
  median_time_to_event_sd = c(.25, .25, .25),
  max_time_to_event = c(18, 18, 18),
  visit_spacing = c(1.2, 1.2, 1.2),
  monthly_rate_mean = c(2, 1, 1),
  monthly_rate_sd = c(.25, .25, .25)
)
```

Here we use the following relevance thresholds for $p_{target}$

```{r define-relevance-threshold}
p_target <- list(A = .3, B = .3, C = .3)
```

## Prior checks

The prior assumptions can be visualized directly using a custom `plot`
method when specifying per-arm sample sizes. The latter are only
relevant for recruitment time. Recruitment rate and response probability
are shown directly. The time to response prior is visualized by the time
to response distribution (prior predictive).

```{r prior-sample}
plot(mdl, refresh = 0)
```

# Computing Probability of Success at planning stage

At planning stage, no data is available yet to condition on. The model
thus samples from the prior predictive distribution and applies the
specified success threshold to each simulated trial. For instance, one
could define success as the observed rate exceeding the target rate.

```{r compute-planning-pos}
n_sim <- 500L # only for speed reasons - increase!

# sample from the prior predictive distribution
tbl_prior_predictive_sample <- sample_prior_predictive(
    mdl, 
    n_per_arm = c(40, 40, 40),
    nsim = n_sim
  )

# calculate number of responses per iteration 
tbl_prior_predictive_sample %>% 
  group_by(iter, group_id) %>% 
  summarize(
    n = n(),
    r = sum(t_recruitment + dt2 < Inf), # a response is observed if the response time point if finite
    .groups = "drop"
  ) %>% 
  mutate(
    `response rate` = r/n,
    success = case_when(
      group_id == "A" ~ `response rate` >= p_target$A,
      group_id == "B" ~ `response rate` >= p_target$B,
      group_id == "C" ~ `response rate` >= p_target$C
    )
  ) %>% 
  group_by(group_id) %>% 
  summarize(
    PoS = mean(success) # calculate observed frequency of "successes
  ) %>% 
  rename(arm = group_id) %>% 
  knitr::kable(
    caption = "Probability of success by arm."
  )
```

## Expected power

Expected power is similar to Probability of Success but conditional on a
relevant response rate. It is thus the natural extension of frequentist
power under uncertainty.

$$
\operatorname{EP} := \operatorname{Pr}\big[\,\operatorname{success}(R)\,|\,\,p \geq p_{\text{target}}\big]
$$

This conditional perspective can be taken by truncating the response
rate prior from below to the above-target region.

```{r condition-on-effect-size}
# change hyperparameters
mdl$logodds_min <- logodds(as.numeric(p_target))

# sample and plot again
plot(mdl, refresh = 0)
```

The corresponding success probability is the expected power.

```{r compute-planning-expected-power}
tbl_prior_predictive_samples <- sample_prior_predictive(
    mdl, 
    n_per_arm = c(40, 40, 40),
    nsim = n_sim
  )

tbl_prior_predictive_summary <- tbl_prior_predictive_samples %>% 
  group_by(iter, group_id) %>% 
  summarize(
    n = n(),
    r = sum(t_recruitment + dt2 < Inf),
    .groups = "drop"
  ) 

tbl_prior_predictive_summary %>% 
  mutate(
    `response rate` = r/n,
    success = case_when(
      group_id == "A" ~ `response rate` >= p_target$A,
      group_id == "B" ~ `response rate` >= p_target$B,
      group_id == "C" ~ `response rate` >= p_target$C
    )
  ) %>% 
  group_by(group_id) %>% 
  summarize(
    `Expected power` = mean(success)
  ) %>% 
  rename(arm = group_id) %>% 
  knitr::kable(
    caption = "Expected power by arm."
  )
```

## Advanced decision boundaries: connection with bhmbasket

`bhmbasket` can be used to implement dynamic borrowing between arms in
Bayesian hierarchical model and `bhmbasket.predict` can interface with
it. The following code demonstrates how an ExNex model can be used to
derive posteriors.

**Note that ...**

-   **currently, the bhmbasket.predict model used to generate samples
    from the prior/posterior predictive distribution is not a
    hierarchical model and does not borrow information between arms
    while the analysis model does.**

-   **bhmbasket does not allow to specify truncated priors. Since we use
    flat priors on the log-odds of response with a conservative upper
    bound of 0.6 this means that the PoS with bhmbasket-posterior is
    higher since the prior leads to more optimistic posteriors.**

```{r bhmbasket-integration}
# this value should be larger in practice
nsim_bhmbasket <- 1000L # gibbs sampler - use more

# remove conditioning of response rate (see expected power) 
# by adjusting lower truncation back to close to 0 (cannot be zero exactly)
mdl$logodds_min <- logodds(c(.001, .001, .001))

# specify priors for bhmbasket analysis (should be consistent)
params <- bhmbasket::setPriorParametersExNex(
  mu_mean   = bhmbasket::logit(0.3), # exchangeable component mean normal prior mean
  mu_sd     = 1, # exchangeable component mean normal prior standard deviation
  tau_scale = 1, # standard deviation of half-normal prior on tau
  mu_j      = bhmbasket::logit(c(.4, .2, .2)), # individual components means
  tau_j     = rep(1, 3), # individual components standard deviations
  w_j       = 0.5 # probability of being exchangeable
)

tbl_bhmbasket_posterior_medians <- tbl_prior_predictive_summary %>%
  # convert to bhmbasket trial objects
  group_by(iter) %>%
  summarize(
    trial = list(bhmbasket::createTrial(n, r))
  ) %>% 
  mutate(
    # map a function over all "trial" realizations which computes the
    # posterior medians
    tmp = purrr::map(trial, function(trial) {
        posterior_medians <- suppressMessages(bhmbasket::performAnalyses(
            scenario_list         = trial,
            method_names          = "exnex",
            prior_parameters_list = params,
            n_mcmc_iterations     = nsim_bhmbasket,
            verbose               = FALSE
          )) %>%
          bhmbasket::getEstimates() %>%
          {as.numeric(.$exnex[,"50%"])} # extract posterior median
        tibble(
          group_id = c("A", "B", "C"),
          posterior_median = posterior_medians
        )
      }
    )
  ) %>% 
  select(-trial) %>% 
  tidyr::unnest(tmp)

# combine the posterior medians with the target rates 
# and check the success criterion
tbl_bhmbasket_posterior_medians %>% 
  mutate(p_target = purrr::map_dbl(group_id, ~p_target[[.]])) %>% 
  group_by(group_id) %>% 
  summarize(
    PoS = mean(posterior_median >= p_target)
  )
```

## Computing dynamic Probability of Success

Looking at a snapshot of the visit data from 18 months into the trial
clearly shows the problem with delayed response data.

```{r restrict-data-to-interim-at-10-months}
tbl_visits_interim <- filter(tbl_visits, t <= 15) 

plot_visits(tbl_visits_interim)
```

Several subjects are still at risk in the respective arms. Counting them
as non-responders is clearly biasing the interim analysis towards lower
response rates. Excluding these can lead to bias if time-to-progression
and time-to-response follow different distributions (conditional on the
final response status). Also, there are small efficiency gains possible
if information about the typical time-to-response is available. If for
instance, an individual is stable after 8 months but the likelihood of
response post 6 months is minimal, the mixture cure rate model will take
that into account and see this individual as more likely to ultimately
become a non-responder.

We first convert the visit data to time-to-first-event,

```{r}
# convert data to time-to-response
tbl_tte_interim <- visits_to_tte(tbl_visits, cutoff = 15)

tbl_tte_interim
```

Next, we sample from the posterior predictive distribution to impute the
outcomes of the individuals still at risk and those still to be
recruited.

```{r sample-from-posterior-predictive}
min_follow_up <- 3 # months, follow up of last individual

tbl_posterior_predictive_summary <- impute_posterior_predictive(
    mdl, data = tbl_tte_interim, seed = 42L, nsim = n_sim, refresh = 0
  ) %>% 
  group_by(iter, group_id) %>%
  tidyr::nest() %>%
  arrange(iter) %>% 
  mutate(
    r = purrr::map_int(data, function(data) {
          with(data,
            sum(t_recruitment + dt2 <= max(t_recruitment) + min_follow_up)
          )
        }
      ),
    n = purrr::map_int(data, nrow)
  ) %>% 
  select(-data)
```

Exactly as before, bhmbasket can be applied to the posterior predictive
samples.

```{r}
tbl_bhmbasket_interim_posterior_medians <- tbl_posterior_predictive_summary %>%
  # convert to bhmbasket trial objects
  group_by(iter) %>%
  summarize(
    trial = list(bhmbasket::createTrial(n, r))
  ) %>% 
  mutate(
    # map a function over all realizations computing the
    # posterior medians
    tmp = purrr::map(trial, function(trial) {
        posterior_medians <- suppressMessages(bhmbasket::performAnalyses(
            scenario_list         = trial,
            method_names          = "exnex",
            prior_parameters_list = params,
            n_mcmc_iterations     = nsim_bhmbasket,
            verbose               = FALSE
          )) %>%
          bhmbasket::getEstimates() %>%
          {as.numeric(.$exnex[,"50%"])} # extract posterior median
        tibble(
          group_id = c("A", "B", "C"),
          posterior_median = posterior_medians
        )
      }
    )
  ) %>% 
  select(-trial) %>% 
  tidyr::unnest(tmp)
```

```{r}
tbl_bhmbasket_interim_posterior_medians %>% 
  mutate(p_target = purrr::map_dbl(group_id, ~p_target[[.]])) %>% 
  group_by(group_id) %>% 
  summarize(
    PoS = mean(posterior_median >= p_target)
  )
```

# Session info

```{r session-info}
sessionInfo()
```
