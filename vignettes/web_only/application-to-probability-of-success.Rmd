---
title: "Application to Probability of Success"
author: "Kevin Kunzmann"
output: rmarkdown::html_vignette
---

```{r knitr-setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 7 / 1.61,
  fig.align = "center",
  cache = TRUE
)
```

```{r setup}
library(oncomsm)
library(ggplot2)
library(dplyr, warn.conflicts = FALSE)
library(future) # parallel processing
library(doFuture)
registerDoFuture()
plan(multisession) # instruct future how to run in parallel
set.seed(42L)
```


**tl;dr:** *A multi-state model allows sampling individual-level 
data. This can be used to sample future trial data from the 
prior-predictive distribution at the planning stage.
This generated trial data can then be used to evaluate quantitative
decision criteria to determine whether the sampled data would lead to a success.
The average success rate over multiple such data sets is the 
Probability of Success.
A similar approach can be taken at any interim time point by sampling from 
the posterior predictive distribution conditioning on any observed data.
This then leads to an updated (or conditional) Probability of Success.*

For a general introduction to the multi-state approach used throughout this
package, see the vignette *Multi-state Models for Early Oncology*.



## Decision criteria and Probability of Success

Let $D_t \in \mathbb{D}$ be the observed (visit) data at time point 
$t$ after the start of the trial.
Let $\tau$ be the stopping time of the trial, 
e.g. the time point when all $n$ individuals have been recruited and 
have reached their minimal follow-up.
The final decision whether or not the trial is considered a success can then
be modeled as a function $\phi: \mathbb{D} \to \{0,1\}$ with 

$$\phi(D_\tau)=1 :\Leftrightarrow D_\tau\ \text{is considered a success}\ . $$

Let $\theta$ be a vector of parameters for a generative model that allows to
sample data $D_\tau|\theta$.
Probability of Success can the be calculated as expected value of the 
decision rule under a prior distribution $f(\cdot)$ over the parameter space:
$$
\operatorname{PoS} = \int \phi(D_\tau) \cdot f(\theta) \operatorname{d}\theta \ .
$$
In practice this integral can be approximated by sampling from the generative
model and calculating the average success rate.

If data $D_t=d_t$ is observed for $t\leq\tau$, one can update the Probability
of Success using Bayes Theorem
$$
\operatorname{PoS}\,|\, (D_t=d_t \ ) = \int \phi(D_\tau\,|\,D_t=d_t) \cdot f(\theta\,|\,D_t=d_t) \operatorname{d}\theta \ .
$$

Examples for such decision rules could be

1. a quantile of the posterior distribution of the response rate being above a
certain relevance threshold,
2. a quantile of the posterior distribution of the PFS6 rate being above a
certain relevance threshold,
3. a quantile of the posterior distribution of PFS being above a certain threshold,
4. or a combination of the above.



Consider a situation with a trial including two different arms 
"A" and "B".
Assume that the following prior for the Weibull SRP multi-state model with 
three arms/groups is given.

```{r prior-specification}
mdl <- create_srp_model(
  group_id = c("A", "B"),
  logodds_mean = logodds(c(0.1, 0.9)),
  logodds_sd = rep(3, 2L),
  median_time_to_next_event = matrix(c(
    2, 6, 24,
    2, 6, 24
  ), byrow = TRUE, nrow = 2, ncol = 3),
  median_time_to_next_event_sd = matrix(3, byrow = TRUE, nrow = 2, ncol = 3),
  visit_spacing = rep(1.2, 2L)
)
```

One can now sample from the prior and visualize the prior assumptions.

```{r sample-from-prios}
smpl_prior <- sample_prior(mdl, seed = 6835L)

plot(mdl, dt = c(0, 36), sample = smpl_prior, n_grid = 25)
```


## A composite ORR and PFS12 success criterion

Assume that success is defined as a combination of a sufficiently high
response rate and a sufficiently high progression-free-survival rate at 12
months:

$$\phi(D_\tau) := \operatorname{Pr}\big[\,\text{ORR} \geq 0.3\ \&\ \text{PFS}_{t=12} \geq 0.4 \, | \, D_\tau\,\big] \geq 0.75$$

This decision criterion can be implemented as the following function:

```{r}
is_success <- function(data, nsim = 250L) {
  set.seed(3819308)
  smpl <- sample_posterior(mdl, data = data, warmup = 150L, nsim = nsim)
  tbl_pfs_orr <- bind_cols(
      sample_pfs_rate(mdl, 12, smpl),
      parameter_sample_to_tibble(mdl, smpl) %>%
        filter(parameter == "p") %>%
        transmute(orr = value)
    )
  res <- tbl_pfs_orr %>%
    group_by(group_id) %>%
    summarize(
      success = mean(pfs >= 0.5 & orr >= 0.3) >= 0.75
    )
  return(res)
}
```

An example of how to apply the criterion to a sample from the prior predictive 
distribution is given below:

```{r, warning=FALSE}
tbl_prior_predictive <- sample_predictive(
    mdl,
    n_per_group = rep(40L, 2),
    sample = smpl_prior,
    nsim = 1L,
    seed = 34930L
  )

is_success(tbl_prior_predictive)
```

Next, we can create a table of multiple prior-predictive samples.
Grouping them by iteration and nesting the data frames results in a data frame
of data frames, where `tbl_prior_predictive$data[[i]]` corresponds to the data
in the i-th resample.

```{r sample-prior-predictive, warning=FALSE}
tbl_prior_predictive <- sample_predictive(
    mdl,
    n_per_group = rep(40L, 2),
    sample = smpl_prior,
    nsim = 100L, # same, here, only for demonstration purposes
    seed = 34930L
  ) %>%
  group_by(iter) %>%
  tidyr::nest() %>%
  ungroup()
print(tbl_prior_predictive)
```

Applying the decision criterion to each of them and averaging over all iterations
is an MCMC approximation of the expected Probability of Success.

```{r, warning=FALSE}
# compute results in parallel
res <- foreach(i = seq_len(nrow(tbl_prior_predictive))) %dopar% {
  is_success(tbl_prior_predictive$data[[i]])
}
# bind results together and aggregate to probability of success
tbl_pos <- bind_rows(res, .id = "iter") %>%
  group_by(group_id) %>%
  summarize(
    PoS = mean(success),
    se  = sd(success) / sqrt(n())
  )
print(tbl_pos)
```



## Probability of Success During the Trial

The Bayesian generative model allows calculating the posterior distribution 
at any time point given the data observed so far.
The future course of the trial can then be sampled from the posterior
predictive distribution.

To illustrate the shift in success probability over time, a single
realization from a point in the parameter space is sampled. 
The probability of success can then be calculated at different time points to
show how the prior shifts.

```{r, warning=FALSE}
mdl_point <- create_srp_model(
  group_id = c("A", "B"),
  logodds_mean = logodds(c(0.5, 0.3)), # chose conflicting ORR parameters
  logodds_sd = rep(0.01, 2L), # almost constant prior = fixed parameter
  median_time_to_next_event = matrix(c(
     4, 8, 24,
     4, 8, 24
  ), byrow = TRUE, nrow = 2, ncol = 3),
  median_time_to_next_event_sd = matrix(0.1, byrow = TRUE, nrow = 2, ncol = 3),
  visit_spacing = c(1.2, 1.2)
)
# sample single realization
tbl_data <- generate_visit_data(
    mdl_point,
    n_per_group = c(40L, 40L),
    recruitment_rate = c(40 / 24, 40 / 24) # recruit in 24 months
  )
print(tbl_data)
```

Next, the snapshot at a sequence of time points of this trial data can be
created.
Interim analyses every 3 months starting at 9 months after first-patient-in
up to 24 months are considered.

```{r}
tbl_data_interims <- tibble(
    t_interim = c(1, 3, 6, 9, 12, 18, 24, 60)
  ) %>%
  mutate(
    data = purrr::map(t_interim, function(t_interim) {
        filter(tbl_data, t <= t_interim) %>% # keep only visits before interim
        visits_to_mstate(start_state = "stable", # convert to mstate format
                         absorbing_states = "progression", now = t_interim)
      })
  )
```

For each such interim data set, the remainder of the trial can be imputed by 
sampling form the posterior-predictive distribution.
Probability of success is then the average success rate in the posterior
predictive sample.
The change of PoS over time is shown below with errorbars corresponding to the
standard error of the simulation.

```{r, warning=FALSE}
# wrap the steps to calculate PoS into a function
pos <- function(tbl, nsim = 50L) {
  tbl_posterior_predictive <- impute(
      mdl, tbl, rep(40L, 2), rep(1, 2L), nsim = nsim) %>%
    group_by(iter) %>%
    tidyr::nest()
  res <- foreach(i = seq_len(nsim)) %dopar% {
    is_success(tbl_posterior_predictive$data[[i]])
  }
  tbl_pos <- bind_rows(res, .id = "iter") %>%
    group_by(group_id) %>%
    summarize(
      PoS = mean(success),
      se  = sd(success) / sqrt(n())
    )
  return(tbl_pos)
}
# apply it to every time point
tbl_pos_over_time <- tbl_data_interims %>%
  mutate(
    pos = purrr::map(data, pos, nsim = 50L)
  ) %>%
  tidyr::unnest(pos)
# plot
ggplot(tbl_pos_over_time) +
  aes(t_interim) +
  geom_errorbar(aes(ymin = PoS - se, ymax = PoS + se, color = group_id),
                width = 1) +
  geom_line(aes(y = PoS, color = group_id), alpha = 0.33) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1), limits = c(0, 1))
```


## Session info

```{r session-info}
sessionInfo()
```
